Mon 29 Sep 2025 16:42:40 INFO  ['run.py']
Mon 29 Sep 2025 16:42:40 INFO  
General Hyper Parameters:
gpu_id = 0
use_gpu = True
seed = 2000
state = INFO
reproducibility = True
data_path = /data/MicroLens-100k
checkpoint_dir = saved
show_progress = True
save_dataset = False
dataset_save_path = None
save_dataloaders = False
dataloaders_save_path = None
log_wandb = False

Training Hyper Parameters:
epochs = 100
train_batch_size = 128
learner = adamW
learning_rate = 0.001
train_neg_sample_args = {'distribution': 'none', 'sample_num': 'none', 'alpha': 'none', 'dynamic': False, 'candidate_num': 0}
eval_step = 1
stopping_step = 5
clip_grad_norm = None
weight_decay = 0.01
loss_decimal_place = 4

Evaluation Hyper Parameters:
eval_args = {'split': {'LS': 'valid_and_test'}, 'order': 'TO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}
repeatable = True
metrics = ['Hit', 'NDCG', 'MRR']
topk = [10, 20]
valid_metric = NDCG@20
valid_metric_bigger = True
eval_batch_size = 128
metric_decimal_place = 4

Dataset Hyper Parameters:
field_separator = 	
seq_separator =  
USER_ID_FIELD = user_id
ITEM_ID_FIELD = item_id
RATING_FIELD = rating
TIME_FIELD = timestamp
seq_len = None
LABEL_FIELD = label
threshold = None
NEG_PREFIX = neg_
load_col = {'inter': ['user_id', 'item_id', 'timestamp']}
unload_col = None
unused_col = None
additional_feat_suffix = None
rm_dup_inter = None
val_interval = None
filter_inter_by_user_or_item = True
user_inter_num_interval = [5,inf)
item_inter_num_interval = [5,inf)
alias_of_user_id = None
alias_of_item_id = None
alias_of_entity_id = None
alias_of_relation_id = None
preload_weight = None
normalize_field = None
normalize_all = None
ITEM_LIST_LENGTH_FIELD = item_length
LIST_SUFFIX = _list
MAX_ITEM_LIST_LENGTH = 50
POSITION_FIELD = position_id
HEAD_ENTITY_ID_FIELD = head_id
TAIL_ENTITY_ID_FIELD = tail_id
RELATION_ID_FIELD = relation_id
ENTITY_ID_FIELD = entity_id
benchmark_filename = None

Other Hyper Parameters: 
worker = 0
wandb_project = recbole
shuffle = True
require_pow = False
enable_amp = False
enable_scaler = False
transform = None
numerical_features = []
discretization = None
kg_reverse_r = False
entity_kg_num_interval = [0,inf)
relation_kg_num_interval = [0,inf)
MODEL_TYPE = ModelType.SEQUENTIAL
device = cuda
id_embedding_dim = 128
num_attention_heads = 8
hidden_size = 128
dropout_prob = 0.2
loss_type = CE
bottleneck = {'dim': 256, 'beta': 1.0, 'weight': 0.1, 'use_stein': True, 'kernel_type': 'rbf', 'bandwidth_factor': 1.0, 'entropy_weight': 0.01, 'adaptive_bandwidth': True, 'min_bandwidth': 0.1, 'max_bandwidth': 10.0, 'alignment_dropout': 0.1, 'layer_norm_eps': 1e-12, 'score_hidden_ratio': 2}
stein = {'kernel_type': 'rbf', 'adaptive_bandwidth': True, 'min_bandwidth': 0.1, 'max_bandwidth': 10.0}
mamba = {'d_state': 16, 'd_conv': 4, 'expand': 2, 'norm_eps': 1e-05, 'hidden_dim': 128, 'num_layers': 2}
feed_forward = {'d_ff': 512, 'dropout': 0.2, 'layer_norm_eps': 1e-12}
attention = {'num_heads': 8, 'dropout': 0.2, 'use_bias': True}
multimodal = {'hidden_size': 256, 'projection_dropout': 0.1, 'fusion_dropout': 0.1, 'feature_dropout': 0.1}
expert = {'num_experts': 4, 'hidden_size': 256, 'output_dim': 128, 'dropout': 0.2}
router = {'hidden_size': 256, 'dropout': 0.1}
text = {'feature_dim': 1024, 'projection_dim': 256, 'layer_norm_eps': 1e-12}
image = {'feature_dim': 1024, 'projection_dim': 256, 'layer_norm_eps': 1e-12}
feature_fusion = {'hidden_size': 256, 'dropout': 0.2, 'activation': 'gelu', 'use_residual': True}
feature_paths = {'image_feature_path': '/data/MicroLens-100k/MicroLens-100k_image_features_CLIPRN50.npy', 'text_feature_path': '/data/MicroLens-100k/MicroLens-100k_title_en_text_features_BgeM3.npy'}
gradient_clip_norm = 2.0
scheduler = cosine
warmup_steps = 2000
gradient_accumulation_steps = 1
memory_optimize = True
cache_size = 3
clear_cache_step = 100
num_workers = 4
prefetch_factor = 2
pin_memory = True
MODEL_INPUT_TYPE = InputType.POINTWISE
eval_type = EvaluatorType.RANKING
single_spec = True
local_rank = 0
valid_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}
test_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}


Mon 29 Sep 2025 16:42:40 INFO  MicroLens-100k
The number of users: 944
Average actions of users: 105.28844114528101
The number of items: 1350
Average actions of items: 73.6004447739066
The number of inters: 99287
The sparsity of the dataset: 92.20911801632141%
Remain Fields: ['user_id', 'item_id', 'timestamp']
Mon 29 Sep 2025 16:42:42 INFO  [Training]: train_batch_size = [128] train_neg_sample_args: [{'distribution': 'none', 'sample_num': 'none', 'alpha': 'none', 'dynamic': False, 'candidate_num': 0}]
Mon 29 Sep 2025 16:42:42 INFO  [Evaluation]: eval_batch_size = [128] eval_args: [{'split': {'LS': 'valid_and_test'}, 'order': 'TO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}]
Mon 29 Sep 2025 16:42:45 INFO  MultiModalMoERec(
  (item_embedding): Embedding(1350, 128, padding_idx=0)
  (image_projection): Linear(in_features=1024, out_features=256, bias=True)
  (text_projection): Linear(in_features=1024, out_features=256, bias=True)
  (id_mamba): MambaLayer(
    (mamba_layers): ModuleList(
      (0-1): 2 x Mamba(
        (in_proj): Linear(in_features=128, out_features=512, bias=False)
        (conv1d): Conv1d(256, 256, kernel_size=(4,), stride=(1,), padding=(3,), groups=256)
        (act): SiLU()
        (x_proj): Linear(in_features=256, out_features=40, bias=False)
        (dt_proj): Linear(in_features=8, out_features=256, bias=True)
        (out_proj): Linear(in_features=256, out_features=128, bias=False)
      )
    )
    (norms): ModuleList(
      (0-1): 2 x LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (dropout): Dropout(p=0.2, inplace=False)
    (layer_scales): ParameterList(
        (0): Parameter containing: [torch.float32 of size 1x1x128 (cuda:0)]
        (1): Parameter containing: [torch.float32 of size 1x1x128 (cuda:0)]
    )
  )
  (fusion_mamba): MambaLayer(
    (mamba_layers): ModuleList(
      (0-1): 2 x Mamba(
        (in_proj): Linear(in_features=128, out_features=512, bias=False)
        (conv1d): Conv1d(256, 256, kernel_size=(4,), stride=(1,), padding=(3,), groups=256)
        (act): SiLU()
        (x_proj): Linear(in_features=256, out_features=40, bias=False)
        (dt_proj): Linear(in_features=8, out_features=256, bias=True)
        (out_proj): Linear(in_features=256, out_features=128, bias=False)
      )
    )
    (norms): ModuleList(
      (0-1): 2 x LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (dropout): Dropout(p=0.2, inplace=False)
    (layer_scales): ParameterList(
        (0): Parameter containing: [torch.float32 of size 1x1x128 (cuda:0)]
        (1): Parameter containing: [torch.float32 of size 1x1x128 (cuda:0)]
    )
  )
  (cross_attention): MultiHeadCrossAttention(
    (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (image_projection): Sequential(
      (0): Linear(in_features=256, out_features=256, bias=True)
      (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (2): Dropout(p=0.2, inplace=False)
    )
    (text_projection): Sequential(
      (0): Linear(in_features=256, out_features=256, bias=True)
      (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (2): Dropout(p=0.2, inplace=False)
    )
    (image_to_text_heads): ModuleList(
      (0-7): 8 x MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=32, out_features=32, bias=True)
      )
    )
    (text_to_image_heads): ModuleList(
      (0-7): 8 x MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=32, out_features=32, bias=True)
      )
    )
    (head_norms): ModuleList(
      (0-7): 8 x LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    )
  )
  (router): ExpertRouter(
    (router): Sequential(
      (0): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
      (1): Linear(in_features=64, out_features=256, bias=True)
      (2): GELU(approximate='none')
      (3): Dropout(p=0.1, inplace=False)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (5): Linear(in_features=256, out_features=4, bias=True)
    )
  )
  (stein_mveb): MultiViewEntropyBottleneck(
    (image_encoder): Sequential(
      (0): Linear(in_features=256, out_features=256, bias=True)
      (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (2): Dropout(p=0.1, inplace=False)
      (3): GELU(approximate='none')
      (4): Linear(in_features=256, out_features=512, bias=True)
    )
    (text_encoder): Sequential(
      (0): Linear(in_features=256, out_features=256, bias=True)
      (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (2): Dropout(p=0.1, inplace=False)
      (3): GELU(approximate='none')
      (4): Linear(in_features=256, out_features=512, bias=True)
    )
    (image_score): Sequential(
      (0): Linear(in_features=256, out_features=512, bias=True)
      (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (2): Dropout(p=0.1, inplace=False)
      (3): GELU(approximate='none')
      (4): Linear(in_features=512, out_features=256, bias=True)
    )
    (text_score): Sequential(
      (0): Linear(in_features=256, out_features=512, bias=True)
      (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (2): Dropout(p=0.1, inplace=False)
      (3): GELU(approximate='none')
      (4): Linear(in_features=512, out_features=256, bias=True)
    )
    (stein_kernel): SteinKernel()
  )
  (experts): ModuleList(
    (0-3): 4 x Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): ReLU()
      (2): Dropout(p=0.2, inplace=False)
    )
  )
  (feature_fusion): Sequential(
    (0): Linear(in_features=1024, out_features=128, bias=True)
    (1): ReLU()
    (2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    (3): Dropout(p=0.1, inplace=False)
  )
  (final_fusion): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    (2): ReLU()
    (3): Dropout(p=0.2, inplace=False)
  )
  (final_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
  (loss_fct): CrossEntropyLoss()
)
Trainable parameters: 2506884
